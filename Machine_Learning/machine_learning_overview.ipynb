{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Machine Learning\n",
    "\n",
    "Machine Learning (ML) is a subfield of Artificial Intelligence that applies math and computation to build models from data. Like modeling tasks in other fields, the goal of machine learning is to cut through the messiness, chaos, and complexity of real-world data to find the underlying relationships in order to represent the system in a meaningful way. All without being explicitly programmed to do so!\n",
    "\n",
    "ML algorithms use data to learn these representations, and are generally based on statistics and mathematical optimization techniques. The algorithms find patterns, trends, or learn relationships in data that may have gone unnoticed by humans.\n",
    "\n",
    "There are different types of algorithms available, and which ones to apply will largely depend on the data and the problem at hand. Algorithms are usually grouped by the following type:\n",
    "\n",
    "- **Supervised learning**: learns patterns from labeled data then applies them to make accurate predictions about new, similar data\n",
    "- **Unsupervised learning**: gives insight into the structure of the data or reduces the number of variables (or features) to what's relevant\n",
    "- **Recommender system**: learns relationships within data to make useful recommendations\n",
    "- **Reinforcement learning**: finds the optimal way to perform a task or learn how to interact in an environment, given a system of rewards and punishments\n",
    "\n",
    "Machine Learning is closely related to predictive statistics, and is sometimes referred to as predictive analytics or predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "\n",
    "Supervised learning is in the realm of building models to make predictions. The data that are fed to the machine learning algorithms include the \"answer\" or outcome the model needs to predict, which is also called the target variable or labels. The model maps the relationships between the independent variables (the input, or features) and the labels, which is later applied to new, unseen data to make predictions going forward.\n",
    "\n",
    "Supervised learning is further broken down by the type of problem - there are **classification** problems, which predict a class or category of an observation, and **regression** problems, which predict a numerical value for an observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Examples of classification algorithms:\n",
    "\n",
    "- **Logistic Regression**: applies log transform on linear regression\n",
    "- **$k$-Nearest Neighbors (kNN)**: finds $k$-nearest neighbors based on a similarity function and uses majority vote to determine the class\n",
    "- **Stochastic Gradient Descent Classifier**: capable of handling large datasets and training in batches (or each instance independently)\n",
    "\n",
    "#### Performance Measures\n",
    "\n",
    "Performance measures tie closely to the confusion matrix, which shows a grid of actual labels against predicted results.\n",
    "\n",
    "| Actual: | Predicted False | Predicted True |\n",
    "| ----- | ----- | ----- |\n",
    "| **Is False** | TN | FP |\n",
    "| **Is True** | FN | TP |\n",
    "\n",
    "\n",
    "A **type I error** (false negative) is when the label is true but the observation is incorrectly classified as false. The probability of a type I error is called **alpha risk**. A **type II error** (false positive) is when the label is false but the observation is incorrectly classified as true. The probability of a type II error is called **beta risk**.\n",
    "\n",
    "- **Accuracy**: the fraction of correct predictions to total predictions $\\frac{TN + TP}{TN + FN + TP + FP}$\n",
    "- **Precision**: the rate of true positives to everything predicted as positive. In other words, when the model claims an observation is positive, it's correct this percent of the time. Good metric to use when what is classified as positive MUST be correct (predicting appropriate videos for kids) $\\frac{TP}{TP + FP}$\n",
    "- **Recall (sensitivity, true positive rate)**: the rate of true positives to everything that is postitive, or in other words, the percent of all the positives the model detects. Good metric to use when you can't let any positives slip through the cracks (predicting malignant tumors so patient receives timely treatment) $\\frac{TP}{TP + FN}$\n",
    "- **F1 Score**: the harmonic mean of precision and recall - the highest value (1) is only possible when both values for precision and recall are high. Good for situations that don't favor either precision or recall, but want to maximize both, or for when the positive class is scarce $\\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}} = \\frac{TP}{TP + \\frac{FN + FP}{2}}$\n",
    "- **Specificity (true negative rate)**: the rate of true negatives to everything that is negative $\\frac{TN}{TN + FP}$\n",
    "- **False positive rate**: rate of negative values falsely classified as positive to everything that is negative $\\frac{FP}{TN + FP}$\n",
    "- **False negative rate**: rate of positive values falsely classified as negative to everything that is  positive $\\frac{FN}{TP + FN}$\n",
    "- **Receiver Operating Characteristic (ROC)**: plots the FPR (incorrectly classified negative values to all negative values) against the TPR/recall/sensitivity (correctly classified positive values to all positive values). As the threshold shifts (to left) to increase the TPR, it incorrectly classifies more and more negative values as positive and vice versa. The total **area under the ROC curve (AUROC)** is 1, indicating a perfect classifier (0.5 is completely random). Similar to precision-recall and F1 - use that when the positive class is scarce or when you care more about the false positives than the false negatives, use ROC otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit learn metrics\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
