{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Representation and Hypothesis Function\n",
    "\n",
    "Given the following assumptions:\n",
    "- Training set contains $m$ observations with $n$ features\n",
    "- Training set of features $X = [(x_1^{(1)}, x_2^{(1)}, \\ldots, x_n^{(1)}), \\ldots , (x_1^{(m)}, x_2^{(m)}, \\ldots, x_n^{(m)}) ]$\n",
    "- Training set of labels $y = [y^{(1)}, \\ldots , y^{(m)}]$\n",
    "- Parameter vector $\\theta = [\\theta_0, \\ldots , \\theta_n]$\n",
    "\n",
    "Goal is to create a hypothesis function $h_{\\theta}(x)$ with parameters (coefficients) $\\theta$ in order to accurately calculate the label for a new, unseen $x$. The form of the hypothesis function is:\n",
    "\n",
    "$$\n",
    "h_{\\theta}(x) = \\theta_0 + \\theta_1x_1 + \\ldots + \\theta_nx_n\n",
    "$$\n",
    "\n",
    "Assuming $x_0 = 1$ for all observations, this is equivalent to:\n",
    "\n",
    "$$\n",
    "h_{\\theta}(x) = \\displaystyle \\sum_{j=0}^{n} \\theta_jx_j^{(i)}\n",
    "$$\n",
    "\n",
    "You can add a new first column to $X$ applying the assumption $x_0^{(i)} = 1$ for all observations. This creates a design matrix of dimension $m \\times (n+1)$ that's compatible to perform matrix multiplication with the $(n+1) \\times 1$ vector $\\theta$. The vectorized representation of the hypothesis function (that results in an $m \\times 1$ vector with $h_{\\theta}(x^{(i)})$ for all observations, $i$ to $m$) is:\n",
    "\n",
    "$$\n",
    "h_{\\theta}(x) = X\\theta\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Adjusting the model's numeric features so they're all on the same scale is important for linear regression, particularly if you use either the gradient descent algorithm to minimize the cost function, or you use regularization.\n",
    "\n",
    "A simple technique is to normalize each feature so it has a mean of zero and standard deviation of 1:\n",
    "\n",
    "$$\n",
    "x = \\frac {x - \\bar{x}}{s}\n",
    "$$\n",
    "\n",
    "Where $\\bar{x}$ is the sample mean of a feature and $s$ is the sample standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalize(X):\n",
    "    '''\n",
    "    Normalizes the features in X where mean value of each\n",
    "        feature is 0 and the standard deviation is 1\n",
    "    X: mxn feature matrix\n",
    "    Output: returns mxn normalized version of X,\n",
    "        the 1xn row vector of means for each feature, and\n",
    "        the 1xn row vector of standard deviations\n",
    "    '''\n",
    "    mean = X.mean()\n",
    "    s = X.std()\n",
    "    X_norm = (X - mean) / s\n",
    "    return (X_norm, mean, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Cost Function\n",
    "\n",
    "Given a training set of $m$ features $X$, $m$ labels $Y$, and $n$ parameters $\\theta$, want to minimize the following cost function:\n",
    "\n",
    "$$\n",
    "J(\\theta_0, \\ldots, \\theta_n) = J(\\theta) = \\frac{1}{2m} \\displaystyle \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})^2\n",
    "$$\n",
    "\n",
    "Vectorized formula:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m} (X\\theta - y)^{T} (X\\theta - y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cost(X, y, theta):\n",
    "    '''\n",
    "    Calculates the cost function J(theta) with given theta parameters\n",
    "        Note: m = # of training observations, n = # of features\n",
    "    X: mx(n+1) design matrix of features\n",
    "    y: mx1 vector of labels\n",
    "    theta: (n+1)x1 vector of parameters\n",
    "    Output: returns J(theta), float\n",
    "    '''\n",
    "    m = len(y)\n",
    "    X_theta_less_y = np.dot(X, theta) - y\n",
    "    J = (1/(2*m)) * np.dot((X_theta_less_y).T, X_theta_less_y)\n",
    "    return J[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Method\n",
    "\n",
    "Gradient descent formula:\n",
    "\n",
    "Repeat until convergence {  \n",
    "$\\quad \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j}J(\\theta) $  \n",
    "}\n",
    "\n",
    "Substituting the partial derivative of the cost function:\n",
    "\n",
    "Repeat {  \n",
    "$ \\quad \\theta_j := \\theta_j - \\frac {\\alpha}{m} \\displaystyle \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)} $  \n",
    "}\n",
    "\n",
    "Vectorized formula:\n",
    "\n",
    "$\\theta := \\theta - \\frac {\\alpha}{m} (X^T (X\\theta - y))$\n",
    "\n",
    "Note that $X$ is the design matrix of features, and should be scaled appropriately to help the \n",
    "gradient descent algorithm converge more quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Gradient descent algorithm to iteratively find the minimum value\n",
    "        of the cost function J(theta)\n",
    "        Note: m = # of training observations, n = # of features\n",
    "    X: mx(n+1) design matrix of scaled features\n",
    "    y: mx1 vector of labels\n",
    "    theta: (n+1)x1 vector of parameters\n",
    "    alpha: the learning rate\n",
    "    num_iters: number of iterations the algorithm should perfomr\n",
    "    Output: returns (n+1)x1 vector of optimal theta parameters and\n",
    "        an array holding the evaluated cost function value (J(theta))\n",
    "        for each iteration\n",
    "    '''\n",
    "    m = len(y)\n",
    "    J_history = np.zeros((num_iters, 1))\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # X' (n+1)xm matrix times h(x)-y mx1 vector -> (n+1)x1 vector\n",
    "        # Scale vector by alpha/m\n",
    "        adj = (alpha / m) * np.dot(X.T, (np.dot(X, theta) - y))\n",
    "\n",
    "        # Simultaneously update thetas\n",
    "        theta = theta - adj\n",
    "\n",
    "        # Save the cost J in every iteration\n",
    "        J_history[i] = calc_cost(X, y, theta)\n",
    "    \n",
    "    return (theta, J_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Equation Method\n",
    "\n",
    "Linear regression has an analytical solution to find the optimal values for $\\theta$ without using an iterative algorithm like gradient descent. You apply calculus to find the minima of the function: find the derivative (or partial derivatives with multiple variables), set to zero, and solve.\n",
    "\n",
    "The vectorized formula (where $X$ is the design matrix) for the solution is:\n",
    "\n",
    "$$\n",
    "\\theta = (X^TX)^{-1} X^Ty\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    '''\n",
    "    Applies the normal equation method to find optimal values for\n",
    "        the parameters theta\n",
    "        Note: m = # of training observations, n = # of features\n",
    "    X: mx(n+1) design matrix of features (scaling unnecessary)\n",
    "    y: mx1 vector of labels\n",
    "    Output: returns (n+1)x1 vector of optimal theta parameters\n",
    "    '''\n",
    "    # theta = pinv(X' * X) * X'* y\n",
    "    inv = np.linalg.pinv(np.dot(X.T, X))\n",
    "    xTy = np.dot(X.T, y)\n",
    "    theta = np.dot(inv, xTy)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SquareFeet</th>\n",
       "      <th>NumBedrooms</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2104</td>\n",
       "      <td>3</td>\n",
       "      <td>399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400</td>\n",
       "      <td>3</td>\n",
       "      <td>369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1416</td>\n",
       "      <td>2</td>\n",
       "      <td>232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>539900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1985</td>\n",
       "      <td>4</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1534</td>\n",
       "      <td>3</td>\n",
       "      <td>314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1427</td>\n",
       "      <td>3</td>\n",
       "      <td>198999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1380</td>\n",
       "      <td>3</td>\n",
       "      <td>212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1494</td>\n",
       "      <td>3</td>\n",
       "      <td>242500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SquareFeet  NumBedrooms   Price\n",
       "0        2104            3  399900\n",
       "1        1600            3  329900\n",
       "2        2400            3  369000\n",
       "3        1416            2  232000\n",
       "4        3000            4  539900\n",
       "5        1985            4  299900\n",
       "6        1534            3  314900\n",
       "7        1427            3  198999\n",
       "8        1380            3  212000\n",
       "9        1494            3  242500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Data - Housing Prices\n",
    "# Source: Coursera Standford Machine Learning course, exercise 1\n",
    "data = pd.read_csv('ex1data2.txt', header=None)\n",
    "data.columns = ['SquareFeet', 'NumBedrooms', 'Price']\n",
    "\n",
    "# Convert data into matrix or array format for linear algebra calculations\n",
    "X = data[['SquareFeet', 'NumBedrooms']].as_matrix()\n",
    "y = np.array(data['Price']).reshape(47, 1)\n",
    "m = len(y)        # Number of training observations\n",
    "n = X.shape[1]    # Number of features\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of normalized design matrix:\n",
      "[[ 1.          0.96415008 -0.87391021]\n",
      " [ 1.          0.52322557 -0.87391021]\n",
      " [ 1.          1.22310574 -0.87391021]\n",
      " [ 1.          0.36225314 -0.87478506]\n",
      " [ 1.          1.74801587 -0.87303536]]\n",
      "Head of non-normalized design matrix:\n",
      "[[  1.00000000e+00   2.10400000e+03   3.00000000e+00]\n",
      " [  1.00000000e+00   1.60000000e+03   3.00000000e+00]\n",
      " [  1.00000000e+00   2.40000000e+03   3.00000000e+00]\n",
      " [  1.00000000e+00   1.41600000e+03   2.00000000e+00]\n",
      " [  1.00000000e+00   3.00000000e+03   4.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create design matrices - add new first column of 1's for x_0\n",
    "x_0 = np.ones((m, 1))\n",
    "\n",
    "# Gradient descent: normalize features first\n",
    "X_norm, mean, s = feature_normalize(X)\n",
    "# print('Mean:\\n{}\\nStd Dev:\\n{}'.format(mean, s))\n",
    "X_norm_design = np.concatenate((x_0, X_norm), axis=1)\n",
    "\n",
    "# Normal equation: no need to normalize features\n",
    "# Create design matrix with non-normalized features\n",
    "X_not_norm_design = np.concatenate((x_0, X), axis=1)\n",
    "\n",
    "print('Head of normalized design matrix:')\n",
    "print(X_norm_design[:5]) \n",
    "print('Head of non-normalized design matrix:')\n",
    "print(X_not_norm_design[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta values from gradient descent:\n",
      "[[ 117312.58404498]\n",
      " [ 153003.61412252]\n",
      " [-102505.55800857]]\n",
      "Theta values from normal equation:\n",
      "[[ 89597.90954361]\n",
      " [   139.21067402]\n",
      " [ -8738.01911255]]\n",
      "Final GD cost: 2058000677\n",
      "Final NE cost: 2043280051\n"
     ]
    }
   ],
   "source": [
    "# Find optimal theta parameters\n",
    "\n",
    "# Gradient descent\n",
    "num_iters = 1000    # Number of iterations for gradient descent\n",
    "alpha = 0.01       # Gradient descent learning rate\n",
    "theta_init = np.zeros((n + 1, 1))\n",
    "theta_gd, J_history = gradient_descent(X_norm_design, y, theta_init, alpha, num_iters)\n",
    "cost_gd = calc_cost(X_norm_design, y, theta_gd)\n",
    "\n",
    "# Normal equation\n",
    "theta_normal = normal_equation(X_not_norm_design, y)\n",
    "cost_normal = calc_cost(X_not_norm_design, y, theta_normal)\n",
    "\n",
    "print('Theta values from gradient descent:\\n{}'.format(theta_gd))\n",
    "print('Theta values from normal equation:\\n{}'.format(theta_normal))\n",
    "print('Final GD cost: {0:.0f}\\nFinal NE cost: {1:.0f}'.format(cost_gd, cost_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price of 1,650 sq-ft, 3 bedroom house:\n",
      "Price from gradient descent: $293641\n",
      "Price from normal equation: $293081\n"
     ]
    }
   ],
   "source": [
    "# Apply linear regression model to predict 1,650 sq-ft, 3 bedroom house\n",
    "house = np.array([1650, 3])\n",
    "\n",
    "# Normalize features, add x_0=1 column, apply gradient descent\n",
    "house_norm = (house - mean) / s\n",
    "house_norm = np.concatenate((np.ones(1), house_norm))\n",
    "price_gd = np.dot(house_norm, theta_gd)\n",
    "\n",
    "# Add x_0=1 column, apply normal equation\n",
    "house_normal = np.concatenate((np.ones(1), house))\n",
    "price_normal = np.dot(house_normal, theta_normal)\n",
    "\n",
    "print('Predicted price of 1,650 sq-ft, 3 bedroom house:')\n",
    "print('Price from gradient descent: ${0:.0f}'.format(price_gd[0]))\n",
    "print('Price from normal equation: ${0:.0f}'.format(price_normal[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
