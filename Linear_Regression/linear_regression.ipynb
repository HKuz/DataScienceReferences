{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SquareFeet</th>\n",
       "      <th>NumBedrooms</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2104</td>\n",
       "      <td>3</td>\n",
       "      <td>399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400</td>\n",
       "      <td>3</td>\n",
       "      <td>369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1416</td>\n",
       "      <td>2</td>\n",
       "      <td>232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>539900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1985</td>\n",
       "      <td>4</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1534</td>\n",
       "      <td>3</td>\n",
       "      <td>314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1427</td>\n",
       "      <td>3</td>\n",
       "      <td>198999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1380</td>\n",
       "      <td>3</td>\n",
       "      <td>212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1494</td>\n",
       "      <td>3</td>\n",
       "      <td>242500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SquareFeet  NumBedrooms   Price\n",
       "0        2104            3  399900\n",
       "1        1600            3  329900\n",
       "2        2400            3  369000\n",
       "3        1416            2  232000\n",
       "4        3000            4  539900\n",
       "5        1985            4  299900\n",
       "6        1534            3  314900\n",
       "7        1427            3  198999\n",
       "8        1380            3  212000\n",
       "9        1494            3  242500"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Data - Housing Prices\n",
    "data = pd.read_csv('ex1data2.txt', header=None)\n",
    "data.columns = ['SquareFeet', 'NumBedrooms', 'Price']\n",
    "\n",
    "X = data[['SquareFeet', 'NumBedrooms']].as_matrix()\n",
    "# y = data['Price']\n",
    "y = np.array(data['Price']).reshape(47, 1)\n",
    "m = len(y)\n",
    "n = X.shape[1]\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model Representation\n",
    "\n",
    "Given the following assumptions:\n",
    "- Training set contains $m$ observations with $n$ features\n",
    "- Training set of features $X = [(x_1^{(1)}, x_2^{(1)}, \\ldots, x_n^{(1)}), \\ldots , (x_1^{(m)}, x_2^{(m)}, \\ldots, x_n^{(m)}) ]$\n",
    "- Training set of labels $y = [y^{(1)}, \\ldots , y^{(m)}]$\n",
    "- Parameter vector $\\theta = [\\theta_0, \\ldots , \\theta_n]$\n",
    "\n",
    "Goal is to create a hypothesis function $h_{\\theta}(x)$ with parameters (coefficients) $\\theta$ in order to accurately calculate the label for a new, unseen $x$. The form of the hypothesis function is:\n",
    "\n",
    "$$\n",
    "h_{\\theta}(x) = \\theta_0 + \\theta_1x_1 + \\ldots + \\theta_nx_n\n",
    "$$\n",
    "\n",
    "Assuming $x_0 = 1$ for all observations, this is equivalent to:\n",
    "\n",
    "$$\n",
    "h_{\\theta}(x) = \\displaystyle \\sum_{j=0}^{n} \\theta_jx_j^{(i)}\n",
    "$$\n",
    "\n",
    "You can add a new first column to $X$ applying the assumption $x_0^{(i)} = 1$ for all observations. This creates a design matrix of dimension $m \\times (n+1)$ that's compatible to perform matrix multiplication with the $(n+1) \\times 1$ vector $\\theta$. The vectorized representation of the hypothesis function (that results in an $m \\times 1$ vector with $h_{\\theta}(x^{(i)})$ for all observations, $i$ to $m$) is:\n",
    "\n",
    "$$\n",
    "h_{\\theta}(x) = X\\theta\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Adjusting the model's numeric features so they're all on the same scale is important for linear regression, particularly if you use the gradient descent algorithm to minimize the cost function, or you use regularization.\n",
    "\n",
    "A simple technique is to normalize each feature so it has a mean of zero and standard deviation of 1:\n",
    "\n",
    "$$\n",
    "x = \\frac {x - \\bar{x}}{s}\n",
    "$$\n",
    "\n",
    "Where $\\bar{x}$ is the sample mean of a feature and $s$ is the sample standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 3)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_normalize(X):\n",
    "    '''\n",
    "    Normalizes the features in X where mean value of each\n",
    "        feature is 0 and the standard deviation is 1\n",
    "    Input: mxn feature matrix X\n",
    "    Output: returns mxn normalized version of X,\n",
    "        the 1xn row vector of means for each feature,\n",
    "        and the 1xn row vector of standard deviations\n",
    "    '''\n",
    "    mean = X.mean()\n",
    "    s = X.std()\n",
    "    X_norm = (X - mean) / s\n",
    "    return (X_norm, mean, s)\n",
    "\n",
    "\n",
    "X_norm, mean, s = feature_normalize(X)\n",
    "# print('Mean:\\n{}\\nStd Dev:\\n{}'.format(mean, s))\n",
    "\n",
    "# Add new first column of 1's\n",
    "x_0 = np.ones((m, 1))\n",
    "X_design = np.concatenate((x_0, X_norm), axis=1)\n",
    "X_design.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Cost Function\n",
    "\n",
    "Given a training set of $m$ features $X$, $m$ labels $Y$, and $n$ parameters $\\theta$, want to minimize the following cost function:\n",
    "\n",
    "$$\n",
    "J(\\theta_0, \\ldots, \\theta_n) = J(\\theta) = \\frac{1}{2m} \\displaystyle \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})^2\n",
    "$$\n",
    "\n",
    "Vectorized formula:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m} (X\\theta - y)^{T} (X\\theta - y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cost(X, y, theta):\n",
    "    '''\n",
    "    Calculates the cost of using theta as the parameters for linear\n",
    "        regression to fit the data points in X and y\n",
    "    X: mx(n+1) design matrix of scaled features\n",
    "    y: mx1 vector of labels\n",
    "    theta: (n+1)x1 vector of parameters\n",
    "    Output: returns J(theta), float\n",
    "    '''\n",
    "    m = len(y)\n",
    "    J = (1/(2*m)) * np.dot((np.dot(X, theta) - y).T, (np.dot(X, theta) - y))\n",
    "    return J[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Method\n",
    "\n",
    "Gradient descent formula:\n",
    "\n",
    "Repeat until convergence {  \n",
    "$\\quad \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j}J(\\theta) $  \n",
    "}\n",
    "\n",
    "Substituting the partial derivative of the cost function:\n",
    "\n",
    "Repeat {  \n",
    "$ \\quad \\theta_j := \\theta_j - \\frac {\\alpha}{m} \\displaystyle \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)} $  \n",
    "}\n",
    "\n",
    "Vectorized formula:\n",
    "\n",
    "$\\theta := \\theta - \\frac {\\alpha}{m} (X^T (X\\theta - y))$\n",
    "\n",
    "Note that $X$ is the design matrix of features, and should be scaled appropriately to help the \n",
    "gradient descent algorithm converge more quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent Variables\n",
    "num_iters = 700  # Number of iterations for gradient descent\n",
    "alpha = 0.01  # Gradient descent learning rate\n",
    "\n",
    "\n",
    "def gradient_descent(X, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Gradient descent algorithm to iteratively find the minimum value\n",
    "        of the cost function J(theta)\n",
    "    X: mx(n+1) design matrix of scaled features\n",
    "    y: mx1 vector of labels\n",
    "    theta: (n+1)x1 vector of parameters\n",
    "    alpha: the learning rate\n",
    "    num_iters: number of iterations the algorithm should perfomr\n",
    "    Output: returns\n",
    "    '''\n",
    "    m = len(y)\n",
    "    J_history = np.zeros((num_iters, 1))\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # X' (n+1)xm matrix times h(x)-y mx1 vector -> (n+1)x1 vector\n",
    "        # Scale vector by alpha/m\n",
    "        adj = (alpha / m) * np.dot(X.T, (np.dot(X, theta) - y))\n",
    "\n",
    "        # Simultaneously update thetas\n",
    "        theta = theta - adj\n",
    "\n",
    "        # Save the cost J in every iteration\n",
    "        J_history[i] = calc_cost(X, y, theta)\n",
    "    \n",
    "    return (theta, J_history)\n",
    "\n",
    "\n",
    "theta = np.zeros((n + 1, 1))\n",
    "theta, J_history = gradient_descent(X_design, y, theta, alpha, num_iters)\n",
    "# theta\n",
    "# J_history[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Equations Method\n",
    "\n",
    "Linear regression has an analytical solution to find the optimal values for $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   2.10400000e+03,   3.00000000e+00],\n",
       "       [  1.00000000e+00,   1.60000000e+03,   3.00000000e+00],\n",
       "       [  1.00000000e+00,   2.40000000e+03,   3.00000000e+00],\n",
       "       [  1.00000000e+00,   1.41600000e+03,   2.00000000e+00],\n",
       "       [  1.00000000e+00,   3.00000000e+03,   4.00000000e+00],\n",
       "       [  1.00000000e+00,   1.98500000e+03,   4.00000000e+00],\n",
       "       [  1.00000000e+00,   1.53400000e+03,   3.00000000e+00],\n",
       "       [  1.00000000e+00,   1.42700000e+03,   3.00000000e+00],\n",
       "       [  1.00000000e+00,   1.38000000e+03,   3.00000000e+00],\n",
       "       [  1.00000000e+00,   1.49400000e+03,   3.00000000e+00]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normal_equation():\n",
    "    '''\n",
    "    TO DO\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "# Create design matrix with non-normalized features\n",
    "X_not_norm_design = np.concatenate((x_0, X), axis=1)\n",
    "X_not_norm_design[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
